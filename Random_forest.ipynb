{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/XTozJttEWTvg229U6iUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manabtikadar/my_project/blob/main/Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Ur0UkW8R6pk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "tfwlLAuVSnsF",
        "outputId": "56c1a0ed-8de2-4465-c860-04930d351519"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c20d9eb-2650-425f-af26-b54067a2ca08\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c20d9eb-2650-425f-af26-b54067a2ca08\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gender_submission.csv to gender_submission.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('train.csv')\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "t5_0sZWDTRIW",
        "outputId": "2d84f2c2-b86e-452d-cf80-e93769bd0885"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f315eab-d373-4e33-9bfa-0147c8ed3235\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f315eab-d373-4e33-9bfa-0147c8ed3235')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f315eab-d373-4e33-9bfa-0147c8ed3235 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f315eab-d373-4e33-9bfa-0147c8ed3235');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82b93de4-ef7d-4429-b776-a3a2e4adaefa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82b93de4-ef7d-4429-b776-a3a2e4adaefa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82b93de4-ef7d-4429-b776-a3a2e4adaefa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "_M3iCzcZkqCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eed4a5c-531d-4f78-a1d4-b32d0e6a7863"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj = (dataset.dtypes == 'object')\n",
        "object_cols = list(obj[obj].index)\n",
        "print(obj)\n",
        "print(\"Categorical variables:\",object_cols)\n",
        "print('No. of. categorical features:',len(object_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvhnggPWl1hR",
        "outputId": "3ac969c3-bb76-4971-ebd4-3898593686a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    False\n",
            "Survived       False\n",
            "Pclass         False\n",
            "Name            True\n",
            "Sex             True\n",
            "Age            False\n",
            "SibSp          False\n",
            "Parch          False\n",
            "Ticket          True\n",
            "Fare           False\n",
            "Cabin           True\n",
            "Embarked        True\n",
            "dtype: bool\n",
            "Categorical variables: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
            "No. of. categorical features: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_dataset = dataset.select_dtypes(include=['int64', 'float64'])\n",
        "print(numerical_dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8itHtMP4mJru",
        "outputId": "24985da1-b0d0-4f06-cb71-65cbad76dd04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
            "0            1         0       3  22.0      1      0   7.2500\n",
            "1            2         1       1  38.0      1      0  71.2833\n",
            "2            3         1       3  26.0      0      0   7.9250\n",
            "3            4         1       1  35.0      1      0  53.1000\n",
            "4            5         0       3  35.0      0      0   8.0500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.loc[dataset['Age'].isnull(),'Age']=np.round(dataset['Age'].mean())\n",
        "dataset.loc[dataset['Embarked'].isnull(),'Embarked']=dataset['Embarked'].value_counts().index[0]"
      ],
      "metadata": {
        "id": "nsqR9mnLmcrh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
      ],
      "metadata": {
        "id": "g03uoU_DondG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train = int(np.floor(0.9 * len(dataset)))\n",
        "dataset = dataset.sample(frac=1, random_state=217)\n",
        "X_train = dataset[features][:nb_train]\n",
        "y_train = dataset['Survived'][:nb_train].values\n",
        "X_test = dataset[features][nb_train:]\n",
        "y_test = dataset['Survived'][nb_train:].values"
      ],
      "metadata": {
        "id": "JFAg0kOzqK2b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train:\\n{X_train}\\n\")\n",
        "print(f\"y_train:\\n{y_train}\\n\")\n",
        "print(f\"X_test:\\n{X_test}\\n\")\n",
        "print(f\"y_test:\\n{y_test}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re6028X5qYbk",
        "outputId": "4d926d49-22b7-4c18-dcf5-bc6dffc11a8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:\n",
            "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "593       3  female  30.0      0      2   7.7500        Q\n",
            "56        2  female  21.0      0      0  10.5000        S\n",
            "24        3  female   8.0      3      1  21.0750        S\n",
            "222       3    male  51.0      0      0   8.0500        S\n",
            "591       1  female  52.0      1      0  78.2667        C\n",
            "..      ...     ...   ...    ...    ...      ...      ...\n",
            "63        3    male   4.0      3      2  27.9000        S\n",
            "855       3  female  18.0      0      1   9.3500        S\n",
            "262       1    male  52.0      1      1  79.6500        S\n",
            "8         3  female  27.0      0      2  11.1333        S\n",
            "412       1  female  33.0      1      0  90.0000        Q\n",
            "\n",
            "[801 rows x 7 columns]\n",
            "\n",
            "y_train:\n",
            "[0 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
            " 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0\n",
            " 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0\n",
            " 1 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0\n",
            " 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0\n",
            " 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0\n",
            " 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0\n",
            " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1\n",
            " 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0\n",
            " 1 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1]\n",
            "\n",
            "X_test:\n",
            "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
            "678       3  female  43.0      1      6   46.9000        S\n",
            "35        1    male  42.0      1      0   52.0000        S\n",
            "462       1    male  47.0      0      0   38.5000        S\n",
            "511       3    male  30.0      0      0    8.0500        S\n",
            "97        1    male  23.0      0      1   63.3583        C\n",
            "..      ...     ...   ...    ...    ...       ...      ...\n",
            "21        2    male  34.0      0      0   13.0000        S\n",
            "342       2    male  28.0      0      0   13.0000        S\n",
            "393       1  female  23.0      1      0  113.2750        C\n",
            "572       1    male  36.0      0      0   26.3875        S\n",
            "658       2    male  23.0      0      0   13.0000        S\n",
            "\n",
            "[90 rows x 7 columns]\n",
            "\n",
            "y_test:\n",
            "[0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1\n",
            " 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bootstrapping\n",
        "*One of the main reasons random forests are so powerul is due to the randomness injected into each tree. What do I mean by this? Each individual decision tree will be constructed on a bootstrapped subset of our data. If our dataset has n observations bootstrapping is the process of sampling n points with replacement. This means that some obsverations in our data set will be selected more than once and some won't be selected at all. We can actually calculate that the probability an observation is omitted from our bootstrapped dataset is (1−1/n)^n. By definition e^−1=limn→∞(1−1/n)^n and since e^−1 = 0.36787.. ≈1/3 ⇒ bootstrapping n samples with replacement will leave out approximately 1/3 of the observations in each distinct tree. Since each individual tree is built using only 2/3 of the data we'll find that most trees will differ significantly from one another. If interested.*\n",
        "\n",
        "*The other great thing that comes with bootstrapping is that we get whats called an out-of-bag error estimate for free. The OOB (out-of-bag) samples are the ≈1/3 observations that were not selected to build a parcticular tree. Once we've built our tree with the n bootstrapped observations we can test each (xi->vector) that was left out and compute the mean prediction error from those samples. We can compute an OOB score for each tree and take the average of all those scores to get an estimate for how accurate our random forests performs, this is essentially leave-one-out cross validation. This will give us an estimate for how accurate our model is without having to formally test it on new data and we'll soon find that it is approximately the same error rate we'll get at test time.*\n",
        "\n"
      ],
      "metadata": {
        "id": "iikiXVfk28yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging\n",
        "*The other great idea that random forests introduce is the concept of bagging. Bagging is the process of growing a tree where each node in the tree looks at every value in our bootstrapped sample in every feature to find the best split in the data at that particular node. This is repeated for all trees.*\n",
        "\n",
        "*Random forests follow the same procedure as bagging, however, the key difference is that on a dataset with p features each tree will only look at a subset of m features where m=(√p). This is injecting even more randomness into the model due to the fact that if we sampled all p features in each tree we would likely be making splits at the same values from the same features in most trees. Given that we are only looking at (√p) features at one time many of the trees will look at a different groups of feature from one another. With this we'll be able to produce many uncorrelated trees which will help us capture a lot of the variability as well as interactions between multiple variables.*"
      ],
      "metadata": {
        "id": "A__MVCu346Qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Algorithm\n",
        "*Suppose we have the following data data {(x⃗ 1,y1),(x⃗ 2,y2),..,(x⃗ n,yn)} where each x⃗ i represents a feature vector [xi1,xi2,...,xim] and let B be the number of trees we want to construct in our forest. We will do the following,*\n",
        "\n",
        "\n",
        "1.   *for b=1 to B:*\n",
        "\n",
        "*   *Draw a bootstrap sample of size n from the data*\n",
        "*   *Grow a decision tree Tb from our bootstrapped sample, by repeating the following steps until the each node consists of 1 class only or until we've reached the minimum node size minsize specified beforehand*\n",
        "        \n",
        "\n",
        "    (i) sample m=p–√ features (where p is the number of features in our dataset)\n",
        "    (ii) compute the information gain for each possible value among the bootstrapped data and m features\n",
        "    (iii) split the node into 2 children nodes  \n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2.   *Output the ensemble of trees {T}B1*\n",
        "\n"
      ],
      "metadata": {
        "id": "Qu38q6QW63M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(p):\n",
        "    if p == 0:\n",
        "        return 0\n",
        "    elif p == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return - (p * np.log2(p) + (1 - p) * np.log2(1-p))"
      ],
      "metadata": {
        "id": "Y0s9NkSH8s6f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(left_child, right_child):\n",
        "    parent = left_child + right_child\n",
        "    p_parent = parent.count(1) / len(parent) if len(parent) > 0 else 0\n",
        "    p_left = left_child.count(1) / len(left_child) if len(left_child) > 0 else 0\n",
        "    p_right = right_child.count(1) / len(right_child) if len(right_child) > 0 else 0\n",
        "    IG_p = calculate_entropy(p_parent)\n",
        "    IG_l = calculate_entropy(p_left)\n",
        "    IG_r = calculate_entropy(p_right)\n",
        "    return IG_p - len(left_child) / len(parent) * IG_l - len(right_child) / len(parent) * IG_r"
      ],
      "metadata": {
        "id": "xx_AwXl29Y69"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bootstrap(X_train,y_train):\n",
        "  bootstrap_indices = list(np.random.choice(range(len(X_train)),len(X_train),replace=True))\n",
        "\n",
        "  oob_indices = [i for i in range(len(X_train)) if i not in bootstrap_indices]\n",
        "  X_bootstrap = X_train.iloc[bootstrap_indices].values\n",
        "  y_bootstrap = y_train[bootstrap_indices]\n",
        "  X_oob = X_train.iloc[bootstrap_indices].values\n",
        "  y_oob = y_train[bootstrap_indices]\n",
        "\n",
        "  return X_bootstrap,y_bootstrap,X_oob,y_oob"
      ],
      "metadata": {
        "id": "X-4yWXl2_Q_g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*At each new iteration we'll use the OOB samples to evaluate the performance of the tree built with the bootstrapped data. So in other words, if we have 100 trees we'll have 100 OOB scores*"
      ],
      "metadata": {
        "id": "DRzg1WcqT8IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oob_score(tree,X_test,y_test):\n",
        "  mislabeled = 0\n",
        "  for i in range(len(X_test)):\n",
        "    pred = predict_tree(tree,X_test[i])\n",
        "    if pred != y_test[i]:\n",
        "      mislabeled += 1\n",
        "\n",
        "  return mislabeled/len(X_test)"
      ],
      "metadata": {
        "id": "qGhHdb9wUFY-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_split_point(X_bootstrap,y_bootstrap,max_features):\n",
        "  features_ls = list()\n",
        "  num_features = len(X_bootstrap[0])\n",
        "\n",
        "  while len(features_ls) <= max_features:\n",
        "    feature_idx = random.sample(range(num_features),1)\n",
        "    if feature_idx not in features_ls:\n",
        "      features_ls.extend(feature_idx)\n",
        "\n",
        "  best_info_gain = -999\n",
        "  node = None\n",
        "\n",
        "  for feature_idx in features_ls:\n",
        "   for split_point in X_bootstrap[:,feature_idx]:\n",
        "      left_child = {'X_bootstrap': [],'y_bootstrap': []}\n",
        "      right_child = {'X_bootstrap': [],'y_bootstrap': []}\n",
        "\n",
        "      if type(split_point) in [int,float]:\n",
        "        for i,value in enumerate(X_bootstrap[:,feature_idx]):\n",
        "          if value <= split_point:\n",
        "            left_child['X_bootstrap'].append(X_bootstrap[i])\n",
        "            left_child['y_bootstrap'].append(y_bootstrap[i])\n",
        "          else:\n",
        "            right_child['X_bootstrap'].append(X_bootstrap[i])\n",
        "            right_child['y_bootstrap'].append(y_bootstrap[i])\n",
        "      else:\n",
        "         for i,value in enumerate(X_bootstrap[:,feature_idx]):\n",
        "           if value == split_point:\n",
        "             left_child['X_bootstrap'].append(X_bootstrap[i])\n",
        "             left_child['y_bootstrap'].append(y_bootstrap[i])\n",
        "           else:\n",
        "              right_child['X_bootstrap'].append(X_bootstrap[i])\n",
        "              right_child['y_bootstrap'].append(y_bootstrap[i])\n",
        "\n",
        "      split_info_gain = information_gain(left_child['y_bootstrap'],right_child['y_bootstrap'])\n",
        "\n",
        "      if split_info_gain >= best_info_gain :\n",
        "         best_info_gain = split_info_gain\n",
        "         left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
        "         right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
        "         node = {'information_gain': split_info_gain,\n",
        "                 'left_child': left_child,\n",
        "                 'right_child': right_child,\n",
        "                 'split_point': split_point,\n",
        "                 'feature_idx': feature_idx}\n",
        "\n",
        "  return node"
      ],
      "metadata": {
        "id": "v11Pcf4dkZ0l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terminal Node\n",
        "We'll next need a function that decides when to stop splitting nodes in a tree and finally output a terminal node (classifies whether the passenger survives or perishes). On a single tree split_node works as follows:\n",
        "\n",
        "1.   Given a node, store the left and right children as left_child & right_child and remove them from the original dictionary\n",
        "2.   Check if either children has 0 observations in them. If one of the children is entirely empty this ultimately means that the best split in the data for that node was unable to differentiate the 2 classes and its best to call terminal_node and return the tree. terminal_node returns the class with the highest counts at the current node.\n",
        "3.   Check if the current depth of the tree has reached the maximum depth. If so, create a terminal node and return the tree.\n",
        "4.   Check if number of observations in the left child at the current node is less than the minimum samples needed to make a split, which will be stored as min_samples_split. If so create a terminal node and return the tree\n",
        "5.   If the left child has more observations than min_samples_split we'll feed that left node into find_split_point again to find the best split point and repeat steps 1 - 6. This is ultimately going to be nesting dictionaries, which we are using to represent each node in our tree.\n",
        "6.   Repeat steps 4 and 5 for the right child node\n",
        "7.   Repeat steps 1 - 6 until each branch has a terminal node\n",
        "\n"
      ],
      "metadata": {
        "id": "8N3PcwST2x8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def terminal_node(node):\n",
        "    y_bootstrap = node['y_bootstrap']\n",
        "    if not y_bootstrap:  # If the node has no labels\n",
        "        return None  # Or return a default class (e.g., 0 or -1)\n",
        "    pred = max(y_bootstrap, key=y_bootstrap.count)\n",
        "    return pred\n"
      ],
      "metadata": {
        "id": "3DBQKKrH3kVh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
        "    left_child = node['left_child']\n",
        "    right_child = node['right_child']\n",
        "\n",
        "    del(node['left_child'])\n",
        "    del(node['right_child'])\n",
        "\n",
        "    # Case 1: Handle empty child nodes (no data)\n",
        "    if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
        "        empty_child = {'y_bootstrap': left_child['y_bootstrap'] + right_child['y_bootstrap']}\n",
        "        node['left_split'] = terminal_node(empty_child)\n",
        "        node['right_split'] = terminal_node(empty_child)\n",
        "        return node\n",
        "\n",
        "    # Case 2: Max depth reached\n",
        "    if depth >= max_depth:\n",
        "        node['left_split'] = terminal_node(left_child)\n",
        "        node['right_split'] = terminal_node(right_child)\n",
        "        return node\n",
        "\n",
        "    # Case 3: Min samples split reached\n",
        "    if len(left_child['X_bootstrap']) <= min_samples_split:\n",
        "        node['left_split'] = terminal_node(left_child)\n",
        "    else:\n",
        "        node['left_split'] = find_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
        "        split_node(node['left_split'], max_features, min_samples_split, max_depth, depth + 1)\n",
        "\n",
        "    if len(right_child['X_bootstrap']) <= min_samples_split:\n",
        "        node['right_split'] = terminal_node(right_child)\n",
        "    else:\n",
        "        node['right_split'] = find_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
        "        split_node(node['right_split'], max_features, min_samples_split, max_depth, depth + 1)"
      ],
      "metadata": {
        "id": "c57EkEYI7g4R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# parameters:\n",
        "\n",
        "1.   n_estimators: (int) The number of trees in the forest.\n",
        "2.   max_features: (int) The number of features to consider when looking for the best split (typically √p)\n",
        "3.   max_depth: (int) The maximum depth of the tree\n",
        "4.   min_samples_split: (int) The minimum number of samples required to split an internal node"
      ],
      "metadata": {
        "id": "X_VJNoV5YHha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(X_bootstrap, y_bootstrap, max_depth, min_samples_split, max_features):\n",
        "    root_node = find_split_point(X_bootstrap, y_bootstrap, max_features)\n",
        "    split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
        "    return root_node"
      ],
      "metadata": {
        "id": "6TQXPRliYtll"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest(X_train,y_train,max_depth,min_samples_split,n_estimators,max_features):\n",
        "  tree_ls = list()\n",
        "  oob_ls = list()\n",
        "\n",
        "  for i in range(n_estimators):\n",
        "    X_bootstrap,y_bootstrap,X_oob,y_oob = draw_bootstrap(X_train,y_train)\n",
        "    tree = build_tree(X_bootstrap,y_bootstrap,max_depth,min_samples_split,max_features)\n",
        "    tree_ls.append(tree)\n",
        "    obb_error = oob_score(tree,X_oob,y_oob)\n",
        "    oob_ls.append(obb_error)\n",
        "\n",
        "  print(f\"OOB estimate: {np.mean(oob_ls):.2f}\")\n",
        "\n",
        "  return tree_ls"
      ],
      "metadata": {
        "id": "wD1tr9CKZtr8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tree(tree, X_test):\n",
        "    feature_idx = tree['feature_idx']\n",
        "\n",
        "    if X_test[feature_idx] <= tree['split_point']:\n",
        "        if type(tree['left_split']) == dict:\n",
        "            return predict_tree(tree['left_split'], X_test)\n",
        "        else:\n",
        "            value = tree['left_split']\n",
        "            return value\n",
        "    else:\n",
        "        if type(tree['right_split']) == dict:\n",
        "            return predict_tree(tree['right_split'], X_test)\n",
        "        else:\n",
        "            return tree['right_split']"
      ],
      "metadata": {
        "id": "Hh6yhW6dexEk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rf(tree_ls, X_test):\n",
        "    pred_ls = list()\n",
        "    for i in range(len(X_test)):\n",
        "        ensemble_preds = [predict_tree(tree, X_test.values[i]) for tree in tree_ls]\n",
        "        final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
        "        pred_ls.append(final_pred)\n",
        "    return np.array(pred_ls)"
      ],
      "metadata": {
        "id": "6DOjKnpnmVqb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = 100\n",
        "max_features = 3\n",
        "max_depth = 10\n",
        "min_samples_split = 2\n",
        "\n",
        "model = random_forest(X_train, y_train, n_estimators=100, max_features=3, max_depth=10, min_samples_split=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfTj1OYbqd7C",
        "outputId": "fd6ec902-a3a4-48cf-81b1-231e8eb44664"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB estimate: 0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict_rf(model, X_test)\n",
        "acc = sum(preds == y_test) / len(y_test)\n",
        "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
      ],
      "metadata": {
        "id": "rjX6PaD7tvHY",
        "outputId": "b6607b21-b7d9-4301-a836-3bf8d2529792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest using library function"
      ],
      "metadata": {
        "id": "JaCydvKHOFJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score , classification_report"
      ],
      "metadata": {
        "id": "TzKsBbNzOR-T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, max_features=3)"
      ],
      "metadata": {
        "id": "M9-vaLTUQ_Z7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Create a ColumnTransformer to one-hot encode categorical features\n",
        "categorical_features = ['Sex', 'Embarked'] # List your categorical features\n",
        "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] # List your numerical features\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_features),  # Passthrough numerical features\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features) # One-hot encode categorical features\n",
        "    ])\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_encoded = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data (using the same encoding as training data)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Now you can fit the model using the encoded data\n",
        "rf.fit(X_train_encoded, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "SBqLzRLRRwZN",
        "outputId": "37fe50d2-baaf-47f5-8034-71223161d75c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, max_features=3, min_samples_split=5)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=3, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, max_features=3, min_samples_split=5)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test_encoded)"
      ],
      "metadata": {
        "id": "GttAdYAVSMsj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eiz1tpgKRhYY",
        "outputId": "d4f40b2a-9f5a-4a1e-98a3-163d6dc30ae3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
            " 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7U-kJKISbmy",
        "outputId": "6065ab3f-c689-4fb9-caf7-159f7e142117"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1\n",
            " 0 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Detailed classification metrics\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDfaHaX4SjDf",
        "outputId": "55e92ab0-be00-4fb4-c741-432a0229c3de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8555555555555555\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88        53\n",
            "           1       0.90      0.73      0.81        37\n",
            "\n",
            "    accuracy                           0.86        90\n",
            "   macro avg       0.87      0.84      0.85        90\n",
            "weighted avg       0.86      0.86      0.85        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf.feature_importances_\n",
        "for i, feature in enumerate(features): # Change dataset.feature_names to dataset.columns\n",
        "    print(f\"{feature}: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al747AAwSszx",
        "outputId": "8433fb1e-7473-42a3-f8c4-b0c7e06cad0e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pclass: 0.0984\n",
            "Sex: 0.1793\n",
            "Age: 0.0512\n",
            "SibSp: 0.0378\n",
            "Parch: 0.2206\n",
            "Fare: 0.2232\n",
            "Embarked: 0.1465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_encoded)\n",
        "print(\"Accuracy with Best Hyperparameters:\", accuracy_score(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57N4fSw1TFE3",
        "outputId": "a5b1429f-452e-4c63-88a0-84253abafd60"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Accuracy with Best Hyperparameters: 0.8444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = rf.predict(X_test_encoded)\n",
        "acc = sum(preds == y_test) / len(y_test)\n",
        "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5kkoso4UEsS",
        "outputId": "de9a84ed-9f09-4af0-dd32-531dbf3b25c4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.856\n"
          ]
        }
      ]
    }
  ]
}